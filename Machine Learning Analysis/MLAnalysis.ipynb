{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required packages and set up the Spark session. This would not be required if using DataBricks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/graeme/anaconda3/envs/ENSF-612/lib/python3.9/site-packages/pyspark'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark;\n",
    "spark = SparkSession.builder.appName('A2').getOrCreate();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the CSV file (n=1000 samples) containing our manual labels as the target vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark.read\n",
    "  .format(\"csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .option(\"multiline\", \"true\")\n",
    "  .option(\"quote\", '\"')  \n",
    "  .option(\"escape\", \"\\\\\")\n",
    "  .option(\"escape\", '\"')\n",
    "  .load(\"GH-React.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparkShape(df):\n",
    "    return (df.count(), len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1000, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[html_url: string, number: int, title: string, labels: string, state: string, locked: boolean, milestone: string, comments: int, created_at: timestamp, updated_at: timestamp, closed_at: timestamp, author_association: string, state_reason: string, assignee.login: string, body: string, Target: string]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape:\",sparkShape(df))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Pipeline\n",
    "### Stage 1\n",
    "The preprocess() function is defined below. It takes in a String formatted as Markdown from GitHub and pre-processes it to return a new string ready for the next stages in our ML Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess(text):\n",
    "    stripped = text.lower()\n",
    "\n",
    "    # remove all headings, bold text, and HTML comments from the Markdown text.\n",
    "    # These items have all been used by the React team in their issue templates on GitHub\n",
    "    headings_pattern = r'(<=\\s|^)#{1,6}(.*?)$'\n",
    "    bold_pattern = r'\\*\\*(.+?)\\*\\*(?!\\*)'\n",
    "    comments_pattern = r'<!--((.|\\n)*?)-->'\n",
    "    combined_pattern = r'|'.join((headings_pattern, bold_pattern, comments_pattern))\n",
    "\n",
    "    stripped = re.sub(combined_pattern, '', stripped)\n",
    "\n",
    "    # find all URLs in the string, and then remove the final directory from each to leave the general URL form\n",
    "    # there may be useful patterns based on what URLs issues are commonly linking to\n",
    "    url_pattern = re.compile(r'(https?://[^\\s]+)')\n",
    "    for url in re.findall(url_pattern, stripped):\n",
    "        new_url = url.rsplit(\"/\", 1)[0]\n",
    "        stripped = stripped.replace(url, new_url)\n",
    "    \n",
    "    non_alpha_pattern = r'[^A-Za-z\\n ]+'\n",
    "    stripped = re.sub(non_alpha_pattern, '', stripped)\n",
    "    \n",
    "    return stripped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!--\\n  Note: if the issue is about documentation or the website, please file it at:\\n  https://github.com/reactjs/reactjs.org/issues/new\\n-->\\n\\n**Do you want to request a *feature* or report a *bug*?**\\nBug\\n\\n**What is the current behavior?**\\nA specific order of unmounting and remounting `unstable_createReturn`s from `react-call-return` causes an invariant violation in `unmountHostComponents`.\\n\\n**Reproduce**\\nThe following sandbox example crashes with an invariant violation when both the `min` and `cycle` props are *odd* numbers greater than zero.\\n\\nhttps://codesandbox.io/s/llyjz19rz7\\n\\n**What is the expected behavior?**\\nThe app does not crash and cycles the number of items in the list.\\n\\n**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**\\n`react` and `react-dom` versions 16.1 and newer, `react-call-return` version 0.5.0\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df.select('body').take(2)\n",
    "test = test[1].body\n",
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "bug\n",
      "\n",
      "\n",
      "a specific order of unmounting and remounting unstablecreatereturns from reactcallreturn causes an invariant violation in unmounthostcomponents\n",
      "\n",
      "\n",
      "the following sandbox example crashes with an invariant violation when both the min and cycle props are odd numbers greater than zero\n",
      "\n",
      "httpscodesandboxios\n",
      "\n",
      "\n",
      "the app does not crash and cycles the number of items in the list\n",
      "\n",
      "\n",
      "react and reactdom versions  and newer reactcallreturn version \n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocess(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2\n",
    "Create a TF-IDF features matrix using TfidfVectorizer from sklearn applied to the title and body of each issue.\n",
    "\n",
    "We will additionally add in the feature 'author_association' from the GitHub issue, as there may be a correlation between Members/Collaborators/Contributors submitting more valid bugs/feature requests than \"None\" users.\n",
    "\n",
    "While lemmatization could have been done earlier in the pre-processsing stage, it is more efficient to lemmatize at this point in a custom_tokenizer() function passed to TfidfVectorizer since tokenization is part of both processses.\n",
    "\n",
    "First, define the tokenizer and vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not run yet. I'm not sure if we want to use this rexex tokenizer instead of built in lemma tokenizer\n",
    "\n",
    "# Technicality: we want to use the regexp-based tokenizer\n",
    "# that is used by CountVectorizer and only use the lemmatization\n",
    "# from spacy. To this end, we replace en_nlp.tokenizer (the spacy tokenizer)\n",
    "# with the regexp-based tokenization.\n",
    "import re\n",
    "# regexp used in CountVectorizer\n",
    "regexp = re.compile('(?u)\\\\b\\\\w\\\\w+\\\\b')\n",
    "# load spacy language model and save old tokenizer\n",
    "en_nlp = spacy.load('en')\n",
    "old_tokenizer = en_nlp.tokenizer\n",
    "# replace the tokenizer with the preceding regexp\n",
    "en_nlp.tokenizer = lambda string: old_tokenizer.tokens_from_list(\n",
    "regexp.findall(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "\n",
    "en_nlp = spacy.load('en')\n",
    "\n",
    "# create a custom tokenizer using the spacy document processing pipeline\n",
    "def custom_tokenizer(document):\n",
    "    doc_spacy = en_nlp(document, entity=False, parse=False)\n",
    "    return [token.lemma_ for token in doc_spacy]\n",
    "\n",
    "vect = TfidfVectorizer(tokenizer=custom_tokenizer, ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the features matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vect.fit_transform(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the target vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.select('Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of target vector: (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of feature matrix:\", sparkShape(X))\n",
    "print(\"Shape of target vector:\", sparkShape(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 3\n",
    "Split the data into training (80%) and validation(20%) sets. We will stratify based on the label since our dataset is imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 4\n",
    "Use cross-validate with our training set to test our model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search for optimizing model\n",
    "\n",
    "Use grid search to find potentially better model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe = make_pipeline(TfidfVectorizer(tokenizer=custom_tokenizer), LogisticRegression())\n",
    "\n",
    "param_grid = {\"logisticregression__C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                \"tfidfvectorizer__ngram_range\": [(1, 1), (1, 2), (1, 3)],\n",
    "                \"tfidfvectorizer__min_df\": [0, 3, 5]}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "grid.fit(text_train, y_train)\n",
    "\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 5\n",
    "Validate our chosen model against the validation set we saved in Stage 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENSF-612",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "758f2f2736c7fa9cea9c3ba7e462cc50ad01011ab3fd1554d8a168a53b5df95b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
